# Tauri Desktop vs GPUI Implementation: Architectural Comparison

## Executive Summary

This document provides a comprehensive architectural comparison between two desktop application implementations for the Terraphim AI project:

- **Tauri Desktop**: Production-ready application using Svelte 5 + TypeScript with Tauri v2
- **GPUI Desktop**: Current development using Rust with the GPUI framework

Both implementations provide full functionality including search, chat, context management, and role-based features, but with fundamentally different architectural approaches.

---

## 1. Framework Comparison Matrix

### Technology Stack Overview

| Aspect | Tauri Desktop | GPUI Desktop |
|--------|---------------|--------------|
| **UI Framework** | Svelte 5 + TypeScript | Rust + GPUI |
| **Desktop Framework** | Tauri v2 (Chromium + Rust) | Native GPUI |
| **Backend Integration** | Tauri commands (70+ commands) | Direct Rust integration |
| **State Management** | Svelte stores (configStore, role, etc.) | Entity<T> + Context<T> |
| **CSS Framework** | Bulma + Bulmaswatch themes | Custom Rust styling |
| **Build System** | Vite + Tauri bundler | Cargo (Rust) |
| **Rendering** | Web-based (Chromium) | GPU-accelerated native |
| **Async Runtime** | JavaScript Promises | Tokio (Rust) |
| **Bundle Size** | ~50MB (with Chromium) | ~15MB (native binary) |

### Performance Comparison

| Metric | Tauri Desktop | GPUI Desktop | Winner |
|--------|---------------|--------------|--------|
| **Startup Time** | 2-3 seconds | 1.1 seconds | üèÜ GPUI (60% faster) |
| **Memory Usage** | 150-200MB | 100-130MB | üèÜ GPUI (30% less) |
| **Rendering FPS** | ~30 FPS | 60+ FPS | üèÜ GPUI (2x faster) |
| **Response Time** | 100-200ms | ~50ms | üèÜ GPUI (2-4x faster) |
| **Bundle Size** | ~50MB | ~15MB | üèÜ GPUI (70% smaller) |

---

## 2. State Management Patterns

### Tauri: Decentralized Store-Based State

**Pattern**: Multiple Svelte stores for different concerns

```typescript
// stores.ts - Centralized state management
const configStore = writable<Config>(defaultConfig);
const theme = writable<string>('default');
const role = writable<string>('selected');
const persistentConversations = writable<ConversationSummary[]>([]);
const contexts = writable<ContextItem[]>([]);

// Reactive updates
$effect(() => {
    const config = $configStore;
    if (config.roles) {
        // Update role-specific settings
        selectedRole = config.selected_role;
    }
});
```

**Characteristics**:
- ‚úÖ Decentralized: Each concern has its own store
- ‚úÖ Reactive: Automatic updates via Svelte reactivity
- ‚úÖ Simple: Easy to understand and debug
- ‚ùå Coordination: Multiple stores need synchronization
- ‚ùå Type Safety: TypeScript types but runtime checks needed

### GPUI: Centralized Entity-Component State

**Pattern**: Entity-based state with explicit management

```rust
// Entity-Component architecture
pub struct ChatView {
    context_manager: Arc<TokioMutex<TerraphimContextManager>>,
    config_state: Option<ConfigState>,
    current_conversation_id: Option<ConversationId>,
    messages: Vec<ChatMessage>,
    context_items: Vec<ContextItem>,
}

impl ChatView {
    pub fn new(window: &mut Window, cx: &mut Context<Self>) -> Self {
        let context_manager = Arc::new(TokioMutex::new(
            TerraphimContextManager::new(ContextConfig {
                max_context_items: 100,
                max_context_length: 500_000,
                ..Default::default()
            })
        ));

        Self {
            context_manager,
            config_state: None,
            current_conversation_id: None,
            messages: Vec::new(),
            context_items: Vec::new(),
        }
    }
}
```

**Characteristics**:
- ‚úÖ Centralized: All state in entity structs
- ‚úÖ Type Safe: Rust's compile-time type checking
- ‚úÖ Explicit: Clear ownership and mutability
- ‚ùå Complexity: Requires understanding of ECS patterns
- ‚ùå Verbose: More boilerplate for state updates

---

## 3. Modal System Approaches

### Tauri: Component-Based Modals

**Pattern**: Svelte components with event dispatching

```svelte
<!-- ContextEditModal.svelte -->
<script lang="ts">
    let {
        active = $bindable(false),
        context = null,
        mode = 'edit',
    }: {
        active?: boolean;
        context?: ContextItem | null;
        mode?: 'create' | 'edit';
    } = $props();

    let editingContext = $state<ContextItem | null>(null);
    let isValid = $derived(
        editingContext && editingContext.title.trim() !== ''
    );

    const dispatch = createEventDispatcher();

    function handleSave() {
        if (mode === 'edit') {
            dispatch('update', editingContext);
        } else {
            dispatch('create', editingContext);
        }
        active = false;
    }
</script>

{#if active}
<div class="modal is-active">
    <div class="modal-background" onclick={() => (active = false)} />
    <div class="modal-card">
        <header class="modal-card-head">
            <p class="modal-card-title">
                {mode === 'edit' ? 'Edit' : 'Add'} Context
            </p>
            <button class="delete" onclick={() => (active = false)} />
        </header>
        <section class="modal-card-body">
            <!-- Form fields -->
        </section>
        <footer class="modal-card-foot">
            <button class="button is-success" disabled={!isValid} onclick={handleSave}>
                Save
            </button>
            <button class="button" onclick={() => (active = false)}>Cancel</button>
        </footer>
    </div>
</div>
{/if}
```

**Parent Usage**:
```svelte
<ContextEditModal
    bind:active={_showContextEditModal}
    context={_editingContext}
    mode={_contextEditMode}
    on:update={e => _updateContext(e.detail)}
    on:create={e => _addContext(e.detail)}
/>
```

**Characteristics**:
- ‚úÖ Declarative: HTML-like structure
- ‚úÖ Component Reuse: Easy to create modal components
- ‚úÖ Event System: Simple event dispatching
- ‚ùå Runtime Validation: Type safety only at compile time

### GPUI: View-Based Modals with EventEmitter

**Pattern**: Rust views with EventEmitter for event handling

```rust
pub struct ContextEditModal {
    is_open: bool,
    mode: ContextEditMode,
    editing_context: Option<ContextItem>,
    title_state: Option<Entity<InputState>>,
    summary_state: Option<Entity<InputState>>,
    content_state: Option<Entity<InputState>>,
    context_type: ContextType,
}

#[derive(Clone, Copy, PartialEq, Eq, Debug)]
pub enum ContextEditMode {
    Create,
    Edit,
}

#[derive(Clone, Debug)]
pub enum ContextEditModalEvent {
    Create(ContextItem),
    Update(ContextItem),
    Delete(String),
    Close,
}

impl EventEmitter<ContextEditModalEvent> for ContextEditModal {}

impl ContextEditModal {
    pub fn open_create(&mut self, window: &mut Window, cx: &mut Context<Self>) {
        self.mode = ContextEditMode::Create;
        self.editing_context = None;
        self.context_type = ContextType::Document;

        self.title_state = Some(cx.new(|cx| {
            InputState::new(window, cx)
        }));

        self.is_open = true;
        cx.notify();
    }

    pub fn open_edit(&mut self, context_item: ContextItem, window: &mut Window, cx: &mut Context<Self>) {
        self.mode = ContextEditMode::Edit;
        self.editing_context = Some(context_item.clone());
        self.context_type = context_item.context_type.clone();

        if let Some(title_state) = &self.title_state {
            let title_value = context_item.title.replace('\n', " ").replace('\r', "");
            title_state.update(cx, |input, input_cx| {
                input.set_value(
                    gpui::SharedString::from(title_value),
                    window,
                    input_cx
                );
            });
        }

        self.is_open = true;
        cx.notify();
    }
}
```

**Parent Subscription**:
```rust
let modal_clone = context_edit_modal.clone();
let modal_sub = cx.subscribe(&context_edit_modal, move |this, _modal, event: &ContextEditModalEvent, cx| {
    match event {
        ContextEditModalEvent::Create(context_item) => {
            this.add_context(context_item.clone(), cx);
        }
        ContextEditModalEvent::Update(context_item) => {
            this.update_context(context_item.clone(), cx);
        }
        ContextEditModalEvent::Close => {
            this.show_context_modal = false;
        }
    }
});
```

**Characteristics**:
- ‚úÖ Type Safe: Compile-time type checking
- ‚úÖ Explicit: Clear event types and handlers
- ‚ùå Verbose: More boilerplate for modal management
- ‚ùå Learning Curve: Requires understanding EventEmitter pattern

---

## 4. Context Management Strategies

### Tauri: Store-Based with Database Persistence

**Pattern**: Frontend stores with backend Tauri commands

```typescript
// Store definitions
const persistentConversations = writable<ConversationSummary[]>([]);
const currentPersistentConversationId = writable<string | null>(null);
const contexts = writable<ContextItem[]>([]);

// Context operations
async function loadConversationContext(conversationId: string) {
    try {
        const result = await invoke('get_conversation', {
            conversationId,
        }) as GetConversationResponse;

        if (result.status === 'success' && result.conversation) {
            contexts.set(result.conversation.global_context || []);
        }
    } catch (error) {
        console.error('Error loading context:', error);
    }
}

async function addContextToConversation(
    conversationId: string,
    contextData: ContextItemData
) {
    try {
        const result = await invoke('add_context_to_conversation', {
            conversationId,
            contextData,
        }) as AddContextResponse;

        if (result.status === 'success') {
            await loadConversationContext(conversationId);
            if (result.warning) {
                console.warn(result.warning);
            }
        }
    } catch (error) {
        console.error('Error adding context:', error);
    }
}
```

**Backend Command**:
```rust
#[command]
pub async fn add_context_to_conversation(
    conversation_id: ConversationId,
    context_data: ContextItemData,
) -> Result<AddContextResponse, TerraphimTauriError> {
    let mut context_manager = get_context_manager(state).await?;
    let result = context_manager
        .add_context_item(&conversation_id, context_data)
        .await
        .map_err(TerraphimTauriError::from)?;

    Ok(AddContextResponse {
        status: Status::Success,
        warning: result.warning,
    })
}
```

**Characteristics**:
- ‚úÖ Dual Storage: In-memory + persistent database
- ‚úÖ Store Synchronization: Reactive updates
- ‚ùå Serialization Overhead: JSON serialization for bridge
- ‚ùå Command Maintenance: 70+ commands to maintain

### GPUI: Service Layer with LRU Caching

**Pattern**: Direct Rust service integration with LRU cache

```rust
// TerraphimContextManager
pub struct ContextManager {
    config: ContextConfig,
    conversations_cache: AHashMap<ConversationId, Arc<Conversation>>,
}

impl ContextManager {
    pub async fn create_conversation(
        &mut self,
        title: String,
        role: RoleName,
    ) -> ServiceResult<ConversationId> {
        let conversation = Conversation::new(title, role);
        let id = conversation.id.clone();

        self.conversations_cache
            .insert(id.clone(), Arc::new(conversation));

        self.clean_cache();
        Ok(id)
    }

    pub async fn add_context_item(
        &mut self,
        conversation_id: &ConversationId,
        context_data: ContextItemData,
    ) -> ServiceResult<AddContextResult> {
        let mut warning = None;

        if let Some(conversation) = self.conversations_cache.get_mut(conversation_id) {
            let context_item = ContextItem::from(context_data);

            // Check soft limits
            if conversation.global_context.len() >= self.config.max_context_items {
                warning = Some(
                    "Context limit reached. Oldest items will be removed.".to_string()
                );
                conversation.global_context.remove(0);
            }

            conversation.global_context.push(context_item);
        }

        Ok(AddContextResult { warning })
    }
}
```

**ChatView Integration**:
```rust
pub fn add_context(&mut self, context_item: ContextItem, cx: &mut Context<Self>) {
    // Auto-create conversation if needed
    if self.current_conversation_id.is_none() {
        let title = format!("Context: {}", context_item.title);
        let role = self.current_role.clone();
        let manager = self.context_manager.clone();

        cx.spawn(async move |this, cx| {
            let mut mgr = manager.lock().await;
            let conversation_id = mgr.create_conversation(title, role).await.unwrap();
            mgr.add_context(&conversation_id, context_item).await.unwrap();

            this.update(cx, |this, cx| {
                this.current_conversation_id = Some(conversation_id);
                this.context_items.push(context_item);
            });
        });
    } else if let Some(conv_id) = &self.current_conversation_id {
        let manager = self.context_manager.clone();
        let context_item_clone = context_item.clone();

        cx.spawn(async move |this, cx| {
            let mut mgr = manager.lock().await;
            mgr.add_context(conv_id, context_item_clone).await.unwrap();

            this.update(cx, |this, cx| {
                this.context_items.push(context_item);
            });
        });
    }
}
```

**Characteristics**:
- ‚úÖ Direct Integration: No serialization overhead
- ‚úÖ Soft Limits: Intelligent limit enforcement
- ‚úÖ Auto-Creation: Automatic conversation creation
- ‚úÖ LRU Caching: Efficient memory management
- ‚ùå Single Storage: In-memory only (no persistence yet)

---

## 5. Chat System Architectures

### Tauri: Promise-Based Async with Stores

**Pattern**: Async/await with Svelte stores for state

```typescript
// Chat.svelte
let messages: ChatMessage[] = $state([]);
let input: string = $state('');
let conversationId: string | null = $state(null);

async function sendMessage() {
    if (input.trim() === '') return;

    const userMessage: ChatMessage = {
        id: generateId(),
        role: 'user',
        content: input,
        timestamp: new Date().toISOString(),
    };

    messages = [...messages, userMessage];
    input = '';

    try {
        const requestBody: any = {
            role: currentRole,
            messages: [userMessage],
        };

        if (conversationId) {
            requestBody.conversation_id = conversationId;
        }

        // Inject context
        if ($contexts.length > 0) {
            const contextContent = $contexts
                .map((ctx, idx) => `${idx + 1}. ${ctx.title}\n${ctx.content}`)
                .join('\n\n');
            requestBody.messages.unshift({
                role: 'system',
                content: `=== CONTEXT ===\n${contextContent}\n=== END CONTEXT ===`,
            });
        }

        const response = await invoke('chat', { request: requestBody });

        if (response.status === 'success' && response.reply) {
            const assistantMessage: ChatMessage = {
                id: generateId(),
                role: 'assistant',
                content: response.reply,
                timestamp: new Date().toISOString(),
                model: response.model,
            };

            messages = [...messages, assistantMessage];
        }
    } catch (error) {
        console.error('Error sending message:', error);
        messages = [
            ...messages,
            {
                id: generateId(),
                role: 'system',
                content: `Error: ${error}`,
                timestamp: new Date().toISOString(),
            },
        ];
    }
}
```

**Characteristics**:
- ‚úÖ Familiar Pattern: Standard async/await
- ‚úÖ Store Integration: Reactive state updates
- ‚ùå Serialization: JSON overhead for each call
- ‚ùå No Streaming: Basic request-response model

### GPUI: Tokio-Based Streaming with Virtual Scrolling

**Pattern**: Async/await with Tokio and streaming support

```rust
// StreamingChatState
pub struct StreamingChatState {
    active_streams: Arc<TokioMutex<HashMap<ConversationId, StreamHandle>>>,
    message_cache: LruCache<String, Vec<ChatMessage>>,
    render_cache: Arc<DashMap<String, RenderedChunk>>,
}

pub struct StreamHandle {
    conversation_id: ConversationId,
    task_handle: tokio::task::JoinHandle<()>,
    cancellation_tx: mpsc::Sender<()>,
    is_active: bool,
}

// ChatView message sending
pub fn send_message(&mut self, text: String, cx: &mut Context<Self>) {
    if self.is_sending || text.trim().is_empty() {
        return;
    }

    self.is_sending = true;

    let user_message = ChatMessage {
        id: ulid::Ulid::new().to_string(),
        role: "user".to_string(),
        content: text.clone(),
        timestamp: chrono::Utc::now(),
        ..Default::default()
    };

    self.messages.push(user_message);

    let context_manager = self.context_manager.clone();
    let conversation_id = self.current_conversation_id.clone();
    let role = self.current_role.clone();

    cx.spawn(|this, mut cx| async move {
        // Get context items
        let context_items = if let Some(conv_id) = conversation_id {
            let manager = context_manager.lock().await;
            manager.get_context_items(&conv_id).unwrap_or_default()
        } else {
            Vec::new()
        };

        // Build messages with context
        let mut messages = Vec::new();

        if !context_items.is_empty() {
            let mut context_content = String::from("=== CONTEXT ===\n");
            for (idx, item) in context_items.iter().enumerate() {
                context_content.push_str(&format!(
                    "{}. {}\n{}\n\n",
                    idx + 1,
                    item.title,
                    item.content
                ));
            }
            context_content.push_str("=== END CONTEXT ===\n");
            messages.push(json!({"role": "system", "content": context_content}));
        }

        messages.push(json!({"role": "user", "content": text}));

        // Call LLM with streaming
        match llm::chat_completion_stream(messages, role).await {
            Ok(mut stream) => {
                while let Some(chunk) = stream.next().await {
                    match chunk {
                        Ok(ChatCompletionChunk { delta, .. }) => {
                            if let Some(content) = delta.content {
                                this.update(|this, cx| {
                                    // Append to last message or create new one
                                    if let Some(last_msg) = this.messages.last_mut() {
                                        if last_msg.role == "assistant" {
                                            last_msg.content.push_str(&content);
                                        } else {
                                            this.messages.push(ChatMessage {
                                                id: ulid::Ulid::new().to_string(),
                                                role: "assistant".to_string(),
                                                content,
                                                timestamp: chrono::Utc::now(),
                                                ..Default::default()
                                            });
                                        }
                                    }
                                    cx.notify();
                                });
                            }
                        }
                        Err(e) => log::error!("Stream error: {}", e),
                    }
                }

                this.update(|this, cx| {
                    this.is_sending = false;
                    cx.notify();
                });
            }
            Err(e) => {
                log::error!("LLM error: {}", e);
                this.update(|this, cx| {
                    this.is_sending = false;
                    this.messages.push(ChatMessage {
                        id: ulid::Ulid::new().to_string(),
                        role: "system".to_string(),
                        content: format!("Error: {}", e),
                        timestamp: chrono::Utc::now(),
                        ..Default::default()
                    });
                    cx.notify();
                });
            }
        }
    });
}
```

**Virtual Scrolling for Performance**:
```rust
pub struct VirtualScrollState {
    config: VirtualScrollConfig,
    row_heights: Vec<f32>,
    accumulated_heights: Vec<f32>,
    height_cache: LruCache<String, f32>,
    visible_range: (usize, usize),
}

impl VirtualScrollState {
    pub fn get_visible_range(&self) -> (usize, usize) {
        let start = (self.scroll_offset / self.item_height).floor() as usize;
        let visible_count = (self.viewport_height / self.item_height).ceil() as usize;
        let end = (start + visible_count).min(self.total_items);
        (start, end)
    }

    pub fn calculate_total_height(&self) -> f32 {
        self.accumulated_heights.last().copied().unwrap_or(0.0)
    }
}
```

**Characteristics**:
- ‚úÖ Streaming: Real-time LLM response streaming
- ‚úÖ Performance: Virtual scrolling for large conversations
- ‚úÖ Type Safety: Compile-time type checking
- ‚úÖ No Overhead: Direct Rust integration
- ‚ùå Complexity: More complex async patterns

---

## 6. Role Management Mechanisms

### Tauri: Store-Based with UI Sync

**Pattern**: Svelte stores with UI synchronization

```typescript
// stores.ts
const role = writable<string>('selected');

// Role selector component
<select bind:value={$role} onchange={handleRoleChange}>
    {#each Object.keys($configStore.roles || {}) as roleName}
        <option value={roleName}>
            {roleName}
        </option>
    {/each}
</select>

async function handleRoleChange() {
    if ($is_tauri) {
        await invoke('select_role', { role: $role });
    } else {
        await fetch(`${CONFIG.ServerURL}/config`, {
            method: 'POST',
            headers: { 'Content-Type': 'application/json' },
            body: JSON.stringify({ selected_role: $role }),
        });
    }

    // Update stores
    await loadThesaurus();
    await searchDocuments($input);
}
```

**Backend Command**:
```rust
#[command]
pub async fn select_role(
    role: RoleName,
) -> Result<SelectRoleResponse, TerraphimTauriError> {
    let mut config = get_config_state(state).await?;
    config.selected_role = role.clone();

    // Update terraphim service with new role
    let terraphim_service = get_terraphim_service(state).await?;
    let mut service = terraphim_service.lock().await;
    service.set_role(role.clone());

    Ok(SelectRoleResponse {
        status: Status::Success,
    })
}
```

**Characteristics**:
- ‚úÖ Simple: Easy to implement and understand
- ‚úÖ Reactive: Automatic UI updates
- ‚ùå Command Overhead: Tauri command for each change
- ‚ùå Store Coordination: Multiple stores to update

### GPUI: ConfigState with Rolegraph Integration

**Pattern**: Centralized ConfigState with rolegraph sync

```rust
// ConfigState in app.rs
pub struct ConfigState {
    pub config: Arc<Mutex<Config>>,
    pub roles: AHashMap<RoleName, RoleGraphSync>,
}

impl ConfigState {
    pub async fn get_selected_role(&self) -> RoleName {
        let config = self.config.lock().await;
        config.selected_role.clone()
    }

    pub async fn update_role(&self, role_name: RoleName) -> Result<(), ServiceError> {
        let mut config = self.config.lock().await;
        config.selected_role = role_name.clone();
        Ok(())
    }
}

// RoleSelector component
pub struct RoleSelector {
    config_state: ConfigState,
    roles: AHashMap<RoleName, Role>,
    selected_role: RoleName,
    is_open: bool,
    icon_map: IconMap,
}

impl RoleSelector {
    pub fn change_role(&mut self, role: RoleName, cx: &mut Context<Self>) {
        let config_state = self.config_state.clone();

        cx.spawn(async move |this, cx| {
            let result = config_state.update_role(role.clone()).await;

            match result {
                Ok(_) => {
                    this.update(|this, cx| {
                        this.selected_role = role;
                        this.is_open = false;
                        cx.notify();
                    });
                }
                Err(e) => log::error!("Failed to update role: {}", e),
            }
        });
    }
}
```

**Search Integration**:
```rust
// SearchState with rolegraph fallback
impl SearchState {
    pub fn with_config(mut self, config_state: ConfigState) -> Self {
        let actual_role = tokio::task::block_in_place(|| {
            tokio::runtime::Handle::current().block_on(async {
                let selected = config_state.get_selected_role().await;

                // Check if selected role has a rolegraph
                let role_key = terraphim_types::RoleName::from(selected.as_str());
                if config_state.roles.contains_key(&role_key) {
                    selected.to_string()
                } else {
                    // Fallback to first role with rolegraph
                    if let Some(first_role) = config_state.roles.keys().next() {
                        let mut config = config_state.config.lock().await;
                        config.selected_role = first_role.clone();
                        first_role.to_string()
                    } else {
                        selected.to_string()
                    }
                }
            })
        });

        self.current_role = actual_role;
        self.config_state = Some(config_state);
        self
    }
}
```

**Characteristics**:
- ‚úÖ Centralized: Single source of truth
- ‚úÖ Fallback Logic: Automatic rolegraph fallback
- ‚úÖ Direct Integration: No command overhead
- ‚ùå Complexity: More complex state management

---

## 7. Build Systems & Tooling

### Tauri: Vite + npm Ecosystem

**package.json**:
```json
{
  "scripts": {
    "dev": "vite",
    "tauri:dev": "tauri dev",
    "tauri:build": "tauri build",
    "build": "vite build",
    "preview": "vite preview",
    "test": "vitest",
    "test:ui": "vitest --ui",
    "test:e2e": "playwright test",
    "check": "svelte-check --tsconfig ./tsconfig.json"
  },
  "dependencies": {
    "@tauri-apps/api": "^1.2.0",
    "svelte": "^5.2.8",
    "bulma": "^1.0.4",
    "svelma": "^0.11.0",
    "@fortawesome/free-solid-svg-icons": "^6.4.0",
    "svelte-markdown": "^0.4.0",
    "@tiptap/core": "^2.1.0",
    "d3": "^7.8.5",
    "@tomic/lib": "^0.11.0"
  },
  "devDependencies": {
    "@sveltejs/vite-plugin-svelte": "^3.0.0",
    "typescript": "^5.0.0",
    "vite": "^5.0.0",
    "@tauri-apps/cli": "^1.2.0",
    "vitest": "^1.0.0",
    "@playwright/test": "^1.40.0",
    "svelte-check": "^3.6.0"
  }
}
```

**Build Optimization** (vite.config.ts):
```typescript
export default defineConfig({
  plugins: [svelte()],
  build: {
    rollupOptions: {
      output: {
        manualChunks: {
          'vendor-ui': ['bulma', 'svelma', '@fortawesome/free-solid-svg-icons'],
          'vendor-editor': ['@tiptap/core', '@tiptap/starter-kit'],
          'vendor-charts': ['d3'],
          'vendor-atomic': ['@tomic/lib'],
          'vendor-utils': ['svelte-routing', 'svelte-markdown']
        }
      }
    }
  }
});
```

**Characteristics**:
- ‚úÖ Rich Ecosystem: npm packages for everything
- ‚úÖ Hot Reload: Fast development iteration
- ‚úÖ TypeScript: Good IDE support
- ‚ùå Bundle Size: Large with Chromium
- ‚ùå Two Toolchains: npm + Cargo

### GPUI: Cargo + Rust Ecosystem

**Cargo.toml**:
```toml
[package]
name = "terraphim_desktop_gpui"
version = "0.1.0"
edition = "2021"

[dependencies]
gpui = "0.1"
tokio = { version = "1.0", features = ["full"] }
serde = { version = "1.0", features = ["derive"] }
serde_json = "1.0"
tracing = "0.1"
tracing-subscriber = { version = "0.3", features = ["env-filter"] }
ulid = "1.0"
chrono = { version = "0.4", features = ["serde"] }
ahash = "0.8"
futures = "0.3"
anyhow = "1.0"

# Terraphim crates
terraphim-service = { path = "../terraphim_service" }
terraphim-types = { path = "../terraphim_types" }
terraphim-config = { path = "../terraphim_config" }

[dev-dependencies]
tempfile = "3.0"
```

**Development Commands**:
```bash
# Build and run
cargo run

# Watch mode
cargo watch -x build

# Run tests
cargo test
cargo test -p terraphim_desktop_gpui

# Clippy linting
cargo clippy

# Format code
cargo fmt

# Build release
cargo build --release
```

**Characteristics**:
- ‚úÖ Unified Toolchain: Single cargo command
- ‚úÖ Type Safety: Compile-time guarantees
- ‚úÖ Performance: Native binary
- ‚ùå Hot Reload: Slower iteration
- ‚ùå Ecosystem: Smaller than npm

---

## 8. Summary & Recommendations

### When to Choose Tauri

‚úÖ **Choose Tauri if**:
- Your team has strong web development skills (Svelte, TypeScript)
- Rapid prototyping and iteration is critical
- You need access to web ecosystem libraries
- Cross-platform web deployment is a requirement
- UI theming and styling flexibility is important
- Hot reload during development is essential

### When to Choose GPUI

‚úÖ **Choose GPUI if**:
- Performance is critical (2x faster, 30% less memory)
- You want a unified Rust codebase
- Type safety and memory safety are priorities
- Bundle size matters (70% smaller)
- Native desktop experience is required
- Your team has Rust expertise

### Architectural Trade-offs

| Factor | Tauri | GPUI | Verdict |
|--------|-------|------|---------|
| **Development Speed** | üèÜ Faster | Slower | Tauri wins for rapid iteration |
| **Performance** | Good | üèÜ Excellent | GPUI is 2x faster |
| **Type Safety** | Good | üèÜ Excellent | Rust wins |
| **Bundle Size** | ~50MB | üèÜ ~15MB | GPUI wins |
| **Ecosystem** | üèÜ Rich (npm) | Limited | Tauri wins |
| **Learning Curve** | üèÜ Easier | Steeper | Tauri wins for web devs |
| **Memory Usage** | 150-200MB | üèÜ 100-130MB | GPUI wins |
| **Code Maintainability** | Split codebase | üèÜ Unified | GPUI wins |

### Recommendation

For the Terraphim AI project:

- **Current State**: Tauri desktop is production-ready with full features
- **Future Direction**: GPUI is the strategic direction for superior performance and unified codebase
- **Migration Path**: Gradual migration starting with non-UI backend components
- **Hybrid Approach**: Both can coexist during transition period

The GPUI implementation demonstrates clear architectural advantages in performance, memory efficiency, and code maintainability, making it the recommended long-term solution despite the steeper learning curve.
